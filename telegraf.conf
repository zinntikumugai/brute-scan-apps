# Telegraf Configuration for Smart Meter CSV to InfluxDB v2
# Compatible with Telegraf 1.35+

[agent]
  ## Default data collection interval for all inputs
  interval = "30s"

  ## Round collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.
  ## Increasing this value allows for longer periods of output downtime
  ## without dropping metrics at the cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  collection_jitter = "0s"

  ## Flush interval controls how often metrics are sent to outputs.
  flush_interval = "10s"
  flush_jitter = "0s"

  ## Precision will be set to nanoseconds if left empty
  precision = "1s"

  ## Override hostname
  hostname = "smartmeter_telegraf"
  omit_hostname = false

  ## Debug mode (set to true for troubleshooting)
  ## Logs all metrics and detailed connection info
  debug = true

  ## Quiet mode (only log errors)
  quiet = false

  ## Log target: "file", "stderr" or "eventlog"
  logtarget = "stderr"

  ## Log level: "error", "warn", "info", "debug", "trace"
  ## Only used when debug = false
  # logfile_rotation_max_size = "10MB"

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# InfluxDB v2 Output Plugin
[[outputs.influxdb_v2]]
  ## InfluxDB v2 server URLs
  urls = ["${INFLUXDB_URL}"]

  ## Authentication token
  token = "${INFLUXDB_TOKEN}"

  ## Organization name
  organization = "${INFLUXDB_ORG}"

  ## Destination bucket to write into
  bucket = "${INFLUXDB_BUCKET}"

  ## Timeout for HTTP messages
  timeout = "10s"

  ## HTTP User-Agent
  user_agent = "telegraf-smartmeter"

  ## Content encoding for write request body
  ## Use "gzip" to compress the request body
  content_encoding = "gzip"

  ## Enable or disable uint support for writing uints influxdb 2.0
  influx_uint_support = true

  ## Log every write to InfluxDB (useful for debugging)
  ## WARNING: This can produce a lot of log output
  # log_level = "debug"

  ## Additional HTTP headers to add to requests
  # [outputs.influxdb_v2.http_headers]
  #   X-Custom-Header = "custom-value"

  ## HTTP Proxy override
  # http_proxy = "http://corporate.proxy:3128"

  ## Optional TLS Config for use on HTTP connections
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false

###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################

# Tail Input Plugin - Monitor Smart Meter CSV Files
[[inputs.tail]]
  ## Files to tail
  ## These accept standard unix glob matching rules, but with the addition of
  ## ** as a "super asterisk". ie:
  ##   /var/log/**.log     -> recursively find all .log files in /var/log
  ##   /var/log/*/*.log    -> find all .log files with a parent dir in /var/log
  ##   /var/log/apache.log -> only tail the apache log file
  files = ["/app/logs/*-smartmeter.csv"]

  ## Read file from beginning
  from_beginning = true

  ## Whether file is a named pipe
  pipe = false

  ## Method used to watch for file updates
  ## Valid options: "inotify" or "poll"
  ## Use "poll" for Docker bind mounts (inotify doesn't work reliably)
  watch_method = "poll"

  ## Poll interval (only used when watch_method = "poll")
  ## How often to check for file updates
  ## Default: 1s (suitable for real-time monitoring)
  # tail_interval = "1s"

  ## Maximum lines of the file to process that have not yet be written by the
  ## output. For best throughput set based on the number of metrics on each
  ## line and the size of the output's metric_batch_size.
  max_undelivered_lines = 1000

  ## Data format to consume
  data_format = "csv"

  ## Number of header rows to skip
  csv_header_row_count = 1

  ## Column names - Long format (1 row per property)
  ## Must match the order in the CSV file
  csv_column_names = [
    "timestamp",
    "unitid",
    "epc",
    "dataid",
    "value"
  ]

  ## Column types
  ## Specify the column types. Options are: "int", "float", "bool", "string"
  ## Must match the order of csv_column_names
  csv_column_types = [
    "string",  # timestamp (parsed separately)
    "string",  # unitid (tag)
    "string",  # epc (tag)
    "string",  # dataid (tag, optional)
    "string"   # value (field, auto-converted)
  ]

  ## Timestamp column name
  csv_timestamp_column = "timestamp"

  ## Timestamp format
  ## Use Go time format: https://golang.org/pkg/time/#Time.Format
  csv_timestamp_format = "2006-01-02T15:04:05.999999"

  ## Timezone
  ## Default timezone assumed if timestamp doesn't specify one
  csv_timezone = "Local"

  ## Columns to use as tags
  ## These columns will become tags in InfluxDB
  csv_tag_columns = ["unitid", "epc", "dataid"]

  ## Skip columns
  # csv_skip_columns = []

  ## Trim leading/trailing whitespace from values
  csv_trim_space = false

  ## Override measurement name
  name_override = "smartmeter_power"

  ## Additional tags to add to metrics
  [inputs.tail.tags]
    host = "smartmeter"
    source = "csv"
    collector = "telegraf"

  ## Log level for this input plugin (optional)
  ## If not set, uses global debug setting
  # log_level = "debug"

###############################################################################
#                            PROCESSOR PLUGINS                                #
###############################################################################

# Converter Processor Plugin - Convert field types
# DISABLED: CSV parser auto-detects types, converter fails on empty strings
# [[processors.converter]]
#   ## Tags to convert
#   # [processors.converter.tags]
#   #   string = []
#
#   ## Fields to convert
#   ## Specify field name and target type
#   ## Available types: "int", "integer", "float", "string", "bool", "tag"
#   [processors.converter.fields]
#     ## Convert to integer
#     integer = ["instant_power_w", "coefficient", "unit", "effective_digits"]
#
#     ## Convert to float
#     float = ["energy_total_kwh", "energy_reverse_kwh"]
#
#   ## Measurement filtering
#   ## Only apply conversion to metrics that match these filters
#   # namepass = ["smartmeter_power"]
#   # fieldpass = ["instant_power_w", "energy_*"]
